<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Ammar's Musings - Sahl Internals - 1</title>
    <meta name="description" content="Ammar's Musings">
    <meta name="author" content="Malik Ammar Faisal">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="stylesheet" href="../fonts/style.css" />
    <link rel="stylesheet" href="../css/default.css" />
    <link rel="stylesheet" href="../css/syntax.css" />
</head>

<body>
    <header>
        <div class="logo">
            <a href="../">Ammar's Musings</a>
        </div>
        <nav>
            <a href="../">Home</a>
            <a href="../about.html">About</a>
            <a href="../contact.html">Contact</a>
            <a href="../archive.html">Archive</a>
        </nav>
    </header>

    <main role="main">
        <h1>Sahl Internals - 1</h1>
        <article>
    <section class="header">
        Posted on January 26, 2024
        
    </section>
    <section>
        <h1 id="prelude">Prelude</h1>
<p>This article primarily discusses some implementation details about my
programming language sahl like how it implements m:n threads in the vm,
some bits about code generation, the development history and future goals.</p>
<h1 id="design-overview">Design Overview</h1>
<p>The Sahl programming language is a statically typed language implemented
in Rust and C. Key design elements include static typing with type
inference, and a concurrency model supporting m:n threads and channels.</p>
<h2 id="syntax">Syntax</h2>
<p>Sahl’s syntax draws inspiration from Rust and Kotlin, with primarily
imperative features.</p>
<h2 id="static-typing">Static Typing</h2>
<p>Sahl employs static typing with type inference. Notably, types are
retained in function prototypes to enhance the inference process. This
design choice aims to strike a balance between flexibility and
predictability in type resolution.</p>
<h1 id="code-generation">Code Generation</h1>
<h2 id="three-address-code">Three Address Code</h2>
<p>Three Address Code generation is exemplified by the following pseudo
code snippet:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode rs"><code class="sourceCode rust"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="cf">match</span> expr <span class="op">{</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  <span class="pp">Expr::</span>Arith <span class="op">{</span>op<span class="op">,</span> lhs<span class="op">,</span> rhs<span class="op">}</span> <span class="op">=&gt;</span> <span class="op">{</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> lhs_reg <span class="op">=</span> compile(lhs)<span class="op">;</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> rhs_reg <span class="op">=</span> compile(rhs)<span class="op">;</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> op <span class="op">==</span> <span class="bu">Add</span> <span class="op">{</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> lhs<span class="op">.</span><span class="kw">type</span> <span class="op">==</span> Int <span class="op">&amp;&amp;</span> rhs<span class="op">.</span><span class="kw">type</span> <span class="op">==</span> Int <span class="op">{</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>        code<span class="op">.</span>push(IAdd(lhs_reg<span class="op">,</span> rhs_reg))<span class="op">;</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>      <span class="op">}</span> <span class="cf">else</span> <span class="op">{</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>        code<span class="op">.</span>push(FAdd(lhs_reg<span class="op">,</span> rhs_reg))<span class="op">;</span> </span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>      <span class="op">}</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>  <span class="op">}</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<h2 id="monomorphisation">Monomorphisation</h2>
<p>The <code>print</code> is implemented for primitives and strings only in the VM and
the native runtime. For lists and tuples a loop is generated at the spot
of invocation which invokes print for whichever primitive is present. In
the initial implementation the type info was used at runtime to print
the primitives and objects but that added an overhead which was
eliminated later.</p>
<h2 id="superinstructions">SuperInstructions</h2>
<p>There are certain sequences on instruction which at the time of codgen
gets combined into a single instruction. These include</p>
<ol type="1">
<li><p><strong>LoadConstOp</strong> which loads a variable and a constant into registers
and performs an operation.</p></li>
<li><p><strong>LoadConstOpStore</strong> which loads a variable and a constant into
registers, performs an operation and stores the result in a
register.</p></li>
<li><p><strong>JmpIfNotCond</strong> which jumps to an instruction if a condition is not
true. It combines the condition check and jump into a single
instruction.</p></li>
</ol>
<h1 id="concurrency-support">Concurrency Support</h1>
<p>This was the main challenging part - m:n threads with channels. Here is
a pseudocode which explains the scheduler.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode rs"><code class="sourceCode rust"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>global_scheduler_queue <span class="op">=</span> []<span class="op">;</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> spawn(thread_vm_obj) <span class="op">{</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>  enqueue(global_scheduler_queue<span class="op">,</span> thread_vm_obj)<span class="op">;</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> poll() <span class="op">{</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">loop</span> <span class="op">{</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    thread_vm_obj <span class="op">=</span> dequeue(global_scheduler_queue)<span class="op">;</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    run(thread_vm_obj)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>  <span class="op">}</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> run(vm_obj) <span class="op">{</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>  <span class="cf">loop</span> <span class="op">{</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">match</span> next_instruction <span class="op">{</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>      CHAN_READ <span class="op">=&gt;</span> <span class="op">{</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> chan_is_empty <span class="op">{</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>          <span class="co">// Give up control</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>          push(global_scheduler_queue)<span class="op">;</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>          <span class="cf">return</span><span class="op">;</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>        <span class="op">}</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>      <span class="op">}</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>      CHAN_WRITE <span class="op">=&gt;</span> <span class="op">{</span></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> chan_is_full <span class="op">{</span></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>          <span class="co">// Give up control</span></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>          push(global_scheduler_queue)<span class="op">;</span></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>          <span class="cf">return</span><span class="op">;</span></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>        <span class="op">}</span> </span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>      <span class="op">}</span></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>  <span class="op">}</span></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> main() <span class="op">{</span></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="dv">0</span><span class="op">..</span>n <span class="op">{</span></span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>    native_thread(poll)</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>  <span class="op">}</span></span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>  vm <span class="op">=</span> new VM<span class="op">;</span></span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>  run(vm)<span class="op">;</span> <span class="co">// Main thread</span></span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<p>The main function of my VM spawns n native threads for polling the
global job queue. The poll functions waits to get a job from the job
queue. I have used mutex and cond vars for synchronization internally.
It is based on the assumption that when a chan is full/empty and has to
be the written to or read from the complementary thread which has to
consume it or write to it is not being run at the moment. This
concurrency model aims to prevent thread starvation, though improvements
for fairness are acknowledged. Here also, the initial</p>
<h1 id="garbage-collector">Garbage Collector</h1>
<p>How to make the gc work across m:n threads? I initially implemented
mark and sweep as it was described in <a href="#https://craftinginterpreters.com">crafting
interpreters</a>. It was naive as every
thread did GC on the objects it had and that lead to live objects being
collected as garbage. I rewrote the VM later to use register based model
and this time I changed the GC to cheney’s (semispace) collector.
Although it still retains the problem of not being able to collect
across threads it is faster than mark and sweep.</p>
<p>The current GC It also happens to be precise instead of conservative.
Stackmaps are emitted for VM to keep track of live objects in the
callframe. Stackmaps are a list 64bit ints wherein i th bit at jth int
in the list is 1 i.e (<code>stackmap[j] &amp; 1 &lt;&lt; i</code>) if the local at index
<code>j * 64 + i</code> is live. It is present as an instruction around an
allocation. On encountering it the <code>vm.callframe.stackmap</code> field is
updated. When the GC is about begin a worklist is prepared by traversing
the callframes and checking their stackmaps.</p>
<h1 id="development-history">Development History</h1>
<ol type="1">
<li><p><strong>Prior Iterations:</strong></p>
<ol type="1">
<li><p><strong>Initial version</strong></p>
<p>Initial parser was written in nom(Rust library) and translated into
Rust enums/structs, running on a virtual machine.</p>
<p>I used the knowledge I had from reading craftinginterpreters but
made it statically typed. Another change I made was to have
separate regs/space in the callframe for locals instead of
putting them on the stack. Stack only had temporary values used
in computation (non variables).</p></li>
<li><p><strong>Introduction of a stack-based virtual machine</strong></p>
<p>I eventually realised using match for rust enums(which was my
compiled code) was slow so I started emitting those enums as
bytes and wrote a vm in c to interpret those.</p></li>
<li><p><strong>Introduction of an AST to NASM transpiler.</strong></p>
<p>I wrote a compiler from my ast to nasm assembly. It was
functional. More than there being no optimizations, I was
calling c functions for basics ops like addition, multiply for
floats.
<a href="#https://github.com/ammarbinfaisal/sahl/blob/fd74a2f89da506cedd7edf2708cd63d53b075002/src/asm.rs">asm.rs</a></p></li>
<li><p><strong>A bytecode to NASM compiler in go:</strong></p>
<p>It read the bytecode and emitted
assembly.<a href="#https://github.com/ammarbinfaisal/sahl/blob/828d8bef82ec3a40083cd938c6ec40deef4355f7/sahl_aot.go">sahl_aot.go</a>.</p></li>
<li><p><strong>Translation from AST to LLVM IR.</strong></p>
<p>I wrote a transpiler from ast itself to llvm ir using inkwell.
<a href="#https://github.com/ammarbinfaisal/sahl/blob/69e4479aff63fe3cd59218a93584557525f8a4a3/src/native.rs">native.rs</a></p></li>
</ol></li>
<li><p><strong>Current Implementation:</strong></p>
<ol type="1">
<li><p>Wrote compiler to three-address IR from AST which was just serialized
as bytes.</p>
<p>I rewrote the virtual machine in a register-based model.</p>
<p>The primary reason to transition from stack based
instructions/vm to register based was speed and the ability to
optimised the latter or even convert to SSA based IR and them
optimise.</p></li>
<li><p>Native compilation to llvm ir using inkwell (rust library) and a
runtime which uses Boehm Allocator/GC.</p>
<p>I chose to do this because the language is entirely statically
typed so this would be easy.</p></li>
</ol></li>
</ol>
<h1 id="future-development-goals">Future Development Goals</h1>
<p>Sahl’s future development aims at enhancing language features and
performance:</p>
<ul>
<li><p>Implementation of an incremental and precise garbage collector to
replace Boehm(native) and Cheney(vm) GCs.</p>
<p>I can do this with train algorithm or treadmill(Baker)’s algorithm.</p>
<p>Having a precise GC in native runtime as well would speed it up and
incremental nature would also give it an edge. We just need to keep
track of where the values are being allocated on the stack to make
it precise. Also, llvm’s mem2reg pass would make this tricky.</p></li>
<li><p>Adoption of safepoints for concurrent garbage collection across m:n
threads.</p></li>
<li><p>Support for interfaces/traits with classes/structs to enhance code
reusability.</p>
<p>I can do this in rust-like traits or java like interfaces. This
would either require monomorphisation or runtime type information.</p></li>
<li><p>Experimentation with a tracing JIT for improved runtime performance.</p></li>
<li><p>Incorporate theoretical ideas which seem feasible and fit the
language’s design.</p></li>
</ul>
    </section>
</article>

    </main>

    <footer>
        Site proudly generated by
        <a href="http://jaspervdj.be/hakyll">Hakyll</a>
    </footer>
</body>

</html>